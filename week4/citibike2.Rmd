---
title: "citibike2"
output:
  pdf_document: default
  html_document: default
date: "2023-06-20"
---

```{r setup, include=FALSE}
library(tidyverse)
library(scales)
library(modelr)
library(broom)
library (lubridate) 
theme_set(theme_bw())
options(repr.plot.width=4, repr.plot.height=3)
```

## Read the File
Split the data into randomly selected training, validation, and test sets, with 90% of the data for training and validating the model, and 10% for a final test set (to be used once and only once towards the end of this exercise).

trips_per_day only contains 90% of data and 10% of data(test data) will be provided later for the final check.
```{r read the file}
trips_per_day=read.table(file="trips_per_day.tsv",sep="\t",header=TRUE)
head(trips_per_day)
```
## Single validate: validation set approach
```{r data fitting model}
#you need to modify the formula accordingly
plotting_model=function(data_train,data_validate,form){
  model <- lm(form, data = data_train)
  
  data_train=data_train%>%
    add_predictions(model) %>%
    mutate(split = "train")
  data_validate=data_validate%>%
    add_predictions(model) %>%
    mutate(split = "validate")
  plot_data=bind_rows(data_train, data_validate)
  
  
  ggplot(plot_data, aes(x = tmin, y = num_trips)) +
    geom_point(aes(color = split)) +
    geom_line(aes(y = pred)) +
    xlab('Minimum temperature') +
    ylab('Daily trips') +
    scale_y_continuous()
}

  
```


```{r validation set approach}
set.seed(42)

validation_set_approach=function(df,training_prop){
  num_rows=nrow(df)
  num_training=floor(training_prop*num_rows)
  
  ndx=sample(1:num_rows,num_training,replace=F)
  data_training=df[ndx,]#my training data
  data_validating=df[-ndx,]#my validation data
  print(nrow(data_training))
  print(nrow(data_validating))
  
  # fit a model for each polynomial degree
  K <- 1:8
  train_err <- c()
  validate_err <- c()
  for (k in K){
    # fit on the training data; you need to modify the formula accordingly
    model <- lm(num_trips ~ poly(tmin, k, raw = T), data=data_training)
    
    # evaluate on the training data
    train_err[k] <- sqrt(mean((predict(model, data_training) - data_training$num_trips)^2))

    # evaluate on the validate data
    validate_err[k] <- sqrt(mean((predict(model, data_validating) - data_validating$num_trips)^2))
  }
  
  plot_data <- data.frame(K, train_err, validate_err) %>%
    gather("split", "error", -K)
  
  ggplot(plot_data, aes(x=K, y=error, color=split)) +
    geom_line() +
    scale_x_continuous(breaks=K) +
    xlab('Polynomial Degree') +
    ylab('RMSE')
  
  #choose the best model
  form=num_trips ~ poly(tmin, 5, raw = T)
  plotting_model(data_training,data_validating,form )
  
}

validation_set_approach(trips_per_day,0.9)
```






























## K-fold cross_validation

```{r k-fold validation}
trips_per_day=trips_per_day%>%mutate(month=month(as.Date(ymd),label=TRUE))

k_fold_validation=function(num_folds,df){

  num_rows=nrow(df)
  df=df%>%
    mutate(fold=(row_number()%%num_folds+1))
  #head(dfn)
  
  
  # fit a model for each polynomial degree
  K <- 1:8
  avg_validate_err <- c()
  se_validate_err <- c()
  for (k in K) {
    # do k-fold cross-validation within each value of k
    validate_err <- c()
    for (f in 1:num_folds) {
      # fit on the training data
      data_train <- filter(df, fold != f)
      model <- lm(num_trips ~ poly(tmin, k, raw = T)+I(prcp==0)+I(snwd==0)*I(snow==0)+month, data=data_train)
  
      # evaluate on the validation data
      data_validate <- filter(df, fold == f)
      validate_err[f] <- sqrt(mean((predict(model, data_validate) - data_validate$num_trips)^2))
    }
  
    # compute the average validation error across folds
    # and the standard error on this estimate
    avg_validate_err[k] <- mean(validate_err)
    se_validate_err[k] <- sd(validate_err) / sqrt(num_folds)
  }
  # plot the validate error, highlighting the value of k with the lowest average error
  plot_data <- data.frame(K, avg_validate_err, se_validate_err)
  ggplot(plot_data, aes(x=K, y=avg_validate_err)) +
    geom_pointrange(aes(ymin=avg_validate_err - se_validate_err,
                        ymax=avg_validate_err + se_validate_err,
                        color=avg_validate_err == min(avg_validate_err))) +
    geom_line(color = "red") +
    scale_x_continuous(breaks=1:12) +
    theme(legend.position="none") +
    xlab('Polynomial Degree') +
    ylab('RMSE on validation data')
}
k_fold_validation(5,trips_per_day)
```

## Different models
uses only the minimum temperature on each day to predict the number of trips taken that day

```{r tmin only, echo=FALSE}
#according to the graph above
#when the polynomial is of degree 4, rmse is minized even though it is not 
#conclusive because of overlapping error bars
model1=lm(num_trips~poly(tmin,4),data=trips_per_day)
rmse(model1,trips_per_day)#rmse that big seems to be reasonable
#summary(model1)

trips_per_day%>%
  ggplot(aes(x=num_trips))+
  geom_histogram()
```
### model2: let us also factor in the effects of weekdays

```{r tmin+weekdays only, echo=FALSE}
trips_per_day=trips_per_day%>%
  mutate(days=wday(as.Date(ymd),label=TRUE))
```
```{r}
model2=lm(num_trips ~ poly(tmin, 4, raw = T)+days, data=trips_per_day)
rmse(model2,trips_per_day)
tidy(model2)

trips_per_day%>%
  add_predictions(model2)%>%
  ggplot(aes(x=pred,y=num_trips,color=days))+
  geom_point()+
  geom_abline(linetype="dashed")+
  #facet_wrap(~days)+
  xlab("predicted")+
  ylab("Actual")

trips_per_day%>%
  add_predictions(model2)%>%
  ggplot(aes(x=tmin,y=num_trips))+
  geom_point()+
  geom_line(aes(y=pred))+
  facet_wrap(~days)+
  xlab("tmin")+
  ylab("Num of Trips")

trips_per_day%>%
  group_by(days)%>%
  summarize(avg_num_trips=mean(num_trips),sd=sd(num_trips),count=n())%>%
  ggplot(aes(x=days,y=avg_num_trips))+
  geom_point()
  
trips_per_day%>%
  ggplot(aes(x=days,y=num_trips))+
  geom_point()
```

according to the model summary and summary table, it seems better that we just differentiate between weekends and weekdays. there are less number of trips that occur on weekends.
```{r weekdays and weekends}
trips_per_day=trips_per_day%>%mutate(weekends_or_not=(days %in% c("Sat","Sun")))
model3=lm(num_trips ~ poly(tmin, 4, raw = T)+weekends_or_not, data=trips_per_day)
rmse(model3,trips_per_day)
tidy(model3)

trips_per_day%>%
  add_predictions(model3)%>%
  ggplot(aes(x=tmin,y=num_trips))+
  geom_point()+
  geom_line(aes(y=pred,linetype=weekends_or_not))
  #facet_wrap(~weekends_or_not)

trips_per_day%>%
  group_by(weekends_or_not)%>%
  ggplot(aes(x=weekends_or_not,y=num_trips))+
  geom_point()
```
###model3:l let us consider the effects of snwd

when there is no snow on the round, people tend to bike more
```{r snwd}
trips_per_day%>%
  ggplot(aes(x=snwd,y=num_trips))+
  geom_point()

model4=lm(num_trips ~ poly(tmin, 4, raw = T)+I(snwd==0),data=trips_per_day)
rmse(model4,trips_per_day)
tidy(model4)
```
let us also consider snow
if it is snowing, people prob do not want to bike
also, snow and snwd seems to interact

```{r snwd+snow}
cor(trips_per_day$snow[1:364],trips_per_day$snwd[2:365])

model5=lm(num_trips ~ poly(tmin, 7, raw = T)+I(snwd==0)*I(snow==0),data=trips_per_day)
rmse(model5,trips_per_day)
summary(model5)
```

##model4: let us consider prcp
when there is precipitation, people would bike less
```{r prcp}
model6=model <- lm(num_trips ~ poly(tmin, 5, raw = T)+I(prcp==0), data=trips_per_day)
rmse(model6,trips_per_day)
tidy(model6)

trips_per_day%>%
  mutate(rain_or_not=prcp==0)%>%
  add_predictions(model6)%>%
  ggplot(aes(x=tmin,y=num_trips))+
  geom_point()+
  geom_line(aes(y=pred,linetype=rain_or_not))
```


```{r prcp}
models=c(as.formula(num_trips~poly(tmin,4)), 
         as.formula(num_trips ~ poly(tmin, 4, raw = T)+days),
         as.formula(num_trips ~ poly(tmin, 4, raw = T)+weekends_or_not),
         as.formula(num_trips ~ poly(tmin, 4, raw = T)+I(snwd==0)),
         as.formula(num_trips ~ poly(tmin, 7, raw = T)+I(snwd==0)*I(snow==0)),
         as.formula(num_trips ~ poly(tmin, 5, raw = T)+I(prcp==0)),
         as.formula(num_trips ~ poly(tmin, 4, raw=T)+I(prcp==0)+weekends_or_not+I(snwd==0)*I(snow==0)+month)
                    )

num_folds=5
df=trips_per_day%>%
    mutate(fold=(row_number()%%num_folds+1))
avg_validate_err <- c()
se_validate_err <- c()

k=1
for (model in models) {
  # do k-fold cross-validation within each value of k
  validate_err <- c()
  for (f in 1:num_folds) {
    # fit on the training data
    data_train <- filter(df, fold != f)
    model <- lm(model, data=data_train)

    # evaluate on the validation data
    data_validate <- filter(df, fold == f)
    validate_err[f] <- sqrt(mean((predict(model, data_validate) - data_validate$num_trips)^2))
  }

  # compute the average validation error across folds
  # and the standard error on this estimate
  avg_validate_err[k] <- mean(validate_err)
  se_validate_err[k] <- sd(validate_err) / sqrt(num_folds)
  k=k+1
}
# plot the validate error, highlighting the value of k with the lowest average error
plot_data <- data.frame(1:7, avg_validate_err, se_validate_err)
ggplot(plot_data, aes(x=X1.7, y=avg_validate_err)) +
  geom_pointrange(aes(ymin=avg_validate_err - se_validate_err,
                      ymax=avg_validate_err + se_validate_err,
                      color=avg_validate_err == min(avg_validate_err))) +
  geom_line(color = "red") +
  scale_x_continuous(breaks=1:12) +
  theme(legend.position="none") +
  xlab('models') +
  ylab('RMSE on validation data')
```

of all the models I have come up so far, the best one is lm(num_trips ~ poly(tmin, 5, raw = T)+I(prcp==0)
